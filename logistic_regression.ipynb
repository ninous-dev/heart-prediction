{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "judicial-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "synthetic-patent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lined-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coral-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cleared-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-sessions",
   "metadata": {},
   "source": [
    "# Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dutch-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/clean_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-spanking",
   "metadata": {},
   "source": [
    "# Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "false-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-berry",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "awful-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuffed-congo",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11627, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abroad-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'RANDID', 'SEX', 'TOTCHOL', 'AGE', 'SYSBP', 'DIABP',\n",
       "       'CURSMOKE', 'CIGPDAY', 'BMI', 'DIABETES', 'BPMEDS', 'HEARTRTE',\n",
       "       'GLUCOSE', 'educ', 'PREVCHD', 'PREVAP', 'PREVMI', 'PREVSTRK', 'PREVHYP',\n",
       "       'TIME', 'PERIOD', 'HDLC', 'LDLC', 'DEATH', 'ANGINA', 'HOSPMI',\n",
       "       'MI_FCHD', 'ANYCHD', 'STROKE', 'CVD', 'HYPERTEN', 'TIMEAP', 'TIMEMI',\n",
       "       'TIMEMIFC', 'TIMECHD', 'TIMESTRK', 'TIMECVD', 'TIMEDTH', 'TIMEHYP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hearing-airfare",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEX', 'TOTCHOL', 'AGE', 'SYSBP', 'DIABP', 'CURSMOKE', 'CIGPDAY', 'BMI',\n",
       "       'DIABETES', 'BPMEDS', 'HEARTRTE', 'GLUCOSE', 'educ', 'PREVCHD',\n",
       "       'PREVAP', 'PREVMI', 'PREVSTRK', 'PREVHYP', 'TIME', 'PERIOD', 'HDLC',\n",
       "       'LDLC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 2: 24].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sunrise-sunday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DEATH', 'ANGINA', 'HOSPMI', 'MI_FCHD', 'ANYCHD', 'STROKE', 'CVD',\n",
       "       'HYPERTEN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 24: 32].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "related-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 8\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:, 2: 24].shape[1], df.iloc[:, 24: 32].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "patient-trance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.loadtxt(data_path, delimiter=\",\",dtype=float, skiprows=1)\n",
    "amax_label = np.amax(data[:, 24:32], axis=1)\n",
    "hist,bins = np.histogram(amax_label) \n",
    "\n",
    "plt.hist(amax_label, bins = bins) \n",
    "plt.title(\"any disease\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-process",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "rotary-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatDeseaseDataset(Dataset): \n",
    "    \n",
    "    def __init__(self, path, any_disease=False):\n",
    "        \n",
    "        self.data = np.loadtxt(path, delimiter=\",\", dtype=float ,skiprows=1)\n",
    "        self.x = torch.from_numpy(self.data[:, 2:24]).to(dtype=torch.long)\n",
    "        if any_disease:\n",
    "            self.y = torch.from_numpy(np.amax(self.data[:, 24:32], axis=1)).to(dtype=torch.long)\n",
    "        else:\n",
    "            self.y = torch.from_numpy(self.data[:, 24:32]).to(dtype=torch.long)\n",
    "        \n",
    "        self.len = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]#, self.original[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-picture",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "representative-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset, batch_size):\n",
    "    lengths = [round(len(dataset) * split) for split in [TRAIN_SPLIT, VALIDATION_SPLIT, TEST_SPLIT]]\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, lengths=lengths, generator=torch.Generator().manual_seed(SEED))\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f'Total dataset: {len(train_dataloader) + len(val_dataloader) + len(test_dataloader)}, '\n",
    "            f'train dataset: {len(train_dataloader)}, val dataset: {len(val_dataloader)}, test_dataset: {len(test_dataloader)}')\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-ensemble",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daily-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multi_prediction(pred, label):\n",
    "    res = 0\n",
    "    nb_prediction = pred.shape[1]\n",
    "\n",
    "    for i in range(nb_prediction):\n",
    "        if pred[0][i].item() == label[0][i].item():\n",
    "            res += 1\n",
    "    return res / nb_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "correct-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    if pred[0].item() == label[0].item():\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-bachelor",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "descending-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, loss='dl', lr=0.1):\n",
    "        possible_loss = {'dl': DiceLoss(), 'nl': nn.NLLLoss(), 'cel':nn.CrossEntropyLoss()}\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.criterion = possible_loss[loss]\n",
    "        self.optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', factor=0.4, patience=2, cooldown=2)\n",
    "        \n",
    "        self.history = {'lr': [], 'loss': [], 'val_loss': []}\n",
    "        self.max_val_loss = float('-inf')\n",
    "        \n",
    "    def fit(self, train_dataloader, val_dataloader, nb_epochs):\n",
    "        for epoch in range(nb_epochs):\n",
    "            print(f'Epoch {epoch} / {nb_epochs}')\n",
    "            train_loss = val_loss = 0.0\n",
    "            \n",
    "            self.model.train()\n",
    "            pbar = tf.keras.utils.Progbar(target=len(train_dataloader))\n",
    "            \n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Clear gradients w.r.t. parameters\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass to get output/logits\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                # Calculate Loss: softmax --> cross entropy loss\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                train_loss += loss\n",
    "\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "\n",
    "                pbar.update(i + 1, values=\n",
    "                            [\n",
    "                                (\"loss\", train_loss.item()/(i + 1)),\n",
    "                                (\"lr\", self.scheduler.optimizer.param_groups[0]['lr'])\n",
    "                            ])\n",
    "                \n",
    "                # Updating parameters\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            \n",
    "            print('Validation')\n",
    "            \n",
    "            self.model.eval()\n",
    "            pbar = tf.keras.utils.Progbar(target=len(val_dataloader))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, batch in enumerate(val_dataloader):\n",
    "                    inputs, labels = batch\n",
    "                    outputs = self.model(inputs)\n",
    "                    val_loss += loss\n",
    "                    pbar.update(i + 1, values=\n",
    "                            [\n",
    "                                (\"loss\", val_loss.item()/(i + 1)),\n",
    "                                (\"lr\", self.scheduler.optimizer.param_groups[0]['lr'])\n",
    "                            ])\n",
    "\n",
    "            train_loss = train_loss / len(train_dataloader)\n",
    "            val_loss = val_loss / len(val_dataloader)\n",
    "            lr = self.scheduler.optimizer.param_groups[0]['lr']\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss > self.max_val_loss:\n",
    "                print(f'Model saved. Loss updated: {self.max_val_loss:.3f} -> {val_loss:.3f}')\n",
    "                self.max_val_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), f'regression_logistice_{val_loss.item()}.pt')\n",
    "            \n",
    "    def evaluate(self, test_dataloader, accuracy_function):\n",
    "        correct = total_loss = total = 0.0\n",
    "        #iterator = 0\n",
    "        \n",
    "        with torch.no_grad():       \n",
    "            # Iterate through test dataset\n",
    "            for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "\n",
    "                pred = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(pred, labels)\n",
    "                total_loss += loss\n",
    "                    \n",
    "                # Total correct predictions\n",
    "                correct += accuracy_function(pred, labels)\n",
    "                #iterator += 1\n",
    "\n",
    "            total_accuracy = 100 * correct / len(test_dataloader)\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}. total loss: {}.'.format(len(test_dataloader), loss.item(), total_accuracy, total_loss))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-policy",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "casual-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-jerusalem",
   "metadata": {},
   "source": [
    "# The logistic regession function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "subsequent-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.final_activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.final_activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-academy",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "musical-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.2\n",
    "VALIDATION_SPLIT = 0.21\n",
    "TRAIN_SPLIT = 1 - TEST_SPLIT - VALIDATION_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "shared-wilson",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: 11627, train dataset: 6860, val dataset: 2442, test_dataset: 2325\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataset = HeatDeseaseDataset(data_path, any_disease=True)\n",
    "train_dataloader, val_dataloader, test_dataloader = create_dataloaders(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-raleigh",
   "metadata": {},
   "source": [
    "# Data verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "young-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ==>\n",
      " tensor([[  1.0000, 221.0000,  46.0000, 125.0000,  88.0000,   1.0000,   5.0000,\n",
      "          24.8100,   0.0000,   0.0000,  72.0000,  87.0000,   1.0000,   0.0000,\n",
      "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   1.0000,  49.0000,\n",
      "         174.0000]], dtype=torch.float64)\n",
      "label ==>\n",
      " tensor([1])\n"
     ]
    }
   ],
   "source": [
    "participant = next(iter(train_dataloader))\n",
    "print('input ==>\\n', participant[0])\n",
    "print('label ==>\\n', participant[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-reflection",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cooperative-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(22,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "collectible-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, loss='nl', lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "arranged-choir",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-1532ea331b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ) \n",
      "\u001b[0;32m<ipython-input-88-f5799922c308>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataloader, val_dataloader, nb_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Forward pass to get output/logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Calculate Loss: softmax --> cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-59c166e2b05e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    nb_epochs=10\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-fault",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(f'regression_logistice_0.720467746257782.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-heart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataloader, accuracy_multi_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-woman",
   "metadata": {},
   "source": [
    "**Test on one participant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        if i ==1:\n",
    "            break\n",
    "    pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "def prediction_analyse(dataloader):\n",
    "    all_predictions = np.array([])\n",
    "    all_labels = np.array([])\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        pred = model(inputs)\n",
    "       # print(pred[0].detach().numpy(), \"label\", labels)\n",
    "        pred = np.where( pred[0].detach().numpy() < 0.5, 0, 1)\n",
    "        #print(pred)\n",
    "        all_predictions = np.append(all_predictions, pred)\n",
    "        all_labels = np.append(all_labels, labels[0].detach().numpy())\n",
    "\n",
    "    #\n",
    "    #print(all_predictions)\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    #\n",
    "    #print(cm)\n",
    "\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=clf.classes_)\n",
    "    display.plot()\n",
    "    plt.show()\n",
    "\n",
    "    TP = cm[1,1] # true positive \n",
    "    TN = cm[0,0] # true negatives\n",
    "    FP = cm[0,1] # false positives\n",
    "    FN = cm[1,0] # false negatif\n",
    "\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    #positive predictive value\n",
    "    PPV = TP / (TP + FP)\n",
    "    #negative predictive value\n",
    "    NPV = TN / (TN + FN)\n",
    "\n",
    "\n",
    "    print(f'sensitivity : {sensitivity}, specificity : {specificity}, PPV : {PPV}, NPV : {NPV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_analyse(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-oliver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-assets",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-shepherd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 2:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "data = np.loadtxt(data_path, delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "Y = np.amax(data[:, 24:32], axis=1)\n",
    "X = data[:, 2:24]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=29)\n",
    "\n",
    "#print(X)\n",
    "\n",
    "pipe = Pipeline(steps=[('classifier', LogisticRegression())])\n",
    "pipe.fit(X_train, y_train)   \n",
    "print(\"The accuracy score of {0} is: {1:.2f}%\".format(LogisticRegression(),(pipe.score(X_test, y_test)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression again with the balanced dataset\n",
    "\n",
    "normalized_df_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "normalized_df_reg_pred = normalized_df_reg.predict(X_test)\n",
    "\n",
    "# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\n",
    "acc = accuracy_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The accuracy score for LogReg is: {round(acc,3)*100}%\")\n",
    "\n",
    "# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "f1 = f1_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The f1 score for LogReg is: {round(f1,3)*100}%\")\n",
    "\n",
    "# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\n",
    "precision = precision_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The precision score for LogReg is: {round(precision,3)*100}%\")\n",
    "\n",
    "# recall score: True Positive Rate(Sensitivity or Recall): When itâ€™s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\n",
    "recall = recall_score(y_test, normalized_df_reg_pred)\n",
    "print(f\"The recall score for LogReg is: {round(recall,3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix LogReg\n",
    "import seaborn as sns\n",
    "\n",
    "cnf_matrix_log = confusion_matrix(y_test, normalized_df_reg_pred)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_log), annot=True,cmap=\"Reds\" , fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix Logistic Regression\\n', y=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
